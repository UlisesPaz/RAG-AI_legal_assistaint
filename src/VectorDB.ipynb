{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vCL7iBt-fe4b"
      },
      "outputs": [],
      "source": [
        "#%pip install langchain_community langchain_text_splitters pypdf langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install -U langchain-ollama langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nCHcjcVfe4d"
      },
      "source": [
        "# Carga de PDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfYj6sNEfe4f",
        "outputId": "575e35d6-22b6-4013-fbdf-432c75c6c9cf"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"./data/Directrices APEC.pdf\" #Ruta al archivo PDF\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SECRwalAfe4f"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M9Z5B5Nfe4h"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m4V9RNEfe4h"
      },
      "outputs": [],
      "source": [
        "%pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "b7pDrRTpfe4i"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5fuaTx5ufe4i",
        "outputId": "c2992220-1fa3-4307-c2eb-fe0c7d6ffa79"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dU4IKJQLfe4i"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4HDFRGkfe4i",
        "outputId": "cdd49e7d-92d6-41fd-ca26-c0181d9f6bed"
      },
      "outputs": [],
      "source": [
        "retriever.get_relevant_documents('consentimiento del individuo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "persistent_client = chromadb.PersistentClient(path='./database')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) #usamos menos tokens que en el anterior debido a que este modelo es inferior\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings, persist_directory='./database')\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever.get_relevant_documents('consentimiento del individuo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOllama(model='llama3.2', temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Crear prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = (\n",
        "    \"Eres un asistente legal experto en responder preguntas de legalidad. \"\n",
        "    \"Usa los siguientes fragmentos de contexto recuperado para proporcionar respuestas precisas, \"\n",
        "    \"fundamentadas en principios legales, normativas aplicables o jurisprudencia relevante. \"\n",
        "    \"Si no sabes la respuesta, indica que no puedes ofrecer una respuesta definitiva. \"\n",
        "    \"Sé claro, directo y profesional, utilizando un máximo de tres oraciones.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag = create_retrieval_chain(retriever, chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = rag.invoke({\"input\": \"consentimiento del individuo\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "chroma_local = Chroma(persist_directory=\"./database\", embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = chroma_local.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever.get_relevant_documents('información personal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prompt():\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ])\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def respuesta(pregunta, llm, chroma_db, prompt):\n",
        "    retriever = chroma_db.as_retriever()\n",
        "\n",
        "    chain = create_stuff_documents_chain(llm, prompt)\n",
        "    rag = create_retrieval_chain(retriever, chain)\n",
        "    \n",
        "    results = rag.invoke({\"input\": pregunta})\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "respuesta('Marco de Privacidad de APEC', llm, chroma_local, prompt())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
